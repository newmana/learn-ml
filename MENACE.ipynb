{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# MENACE: Machine Educable Noughts And Crosses Engine\n",
    "\n",
    "## Introduction\n",
    "\n",
    "MENACE (Machine Educable Noughts And Crosses Engine) is a mechanical learning machine designed by Donald Michie in 1961. It was created to demonstrate the concept of reinforcement learning, long before modern machine learning techniques were developed.\n",
    "\n",
    "## Historical Context\n",
    "\n",
    "Donald Michie (1923-2007) was a British researcher and a pioneer in artificial intelligence. He worked at Bletchley Park during World War II, contributing to the effort to break the German Enigma code alongside Alan Turing. After the war, Michie pursued a career in biology before transitioning to artificial intelligence research.\n",
    "\n",
    "MENACE was conceived during a time when computers were still in their infancy and not widely accessible. Michie's invention demonstrated that learning algorithms could be implemented without complex electronic computers, using simple mechanical means.\n",
    "\n",
    "## How MENACE Works\n",
    "\n",
    "MENACE uses a collection of matchboxes to \"learn\" how to play Tic-Tac-Toe (also known as Noughts and Crosses). Here's a brief overview of its operation:\n",
    "\n",
    "1. **Representation**: Each possible game state is represented by a matchbox.\n",
    "2. **Decision Making**: Inside each matchbox are colored beads, each color corresponding to a possible move.\n",
    "3. **Learning**: \n",
    "   - To make a move, MENACE randomly selects a bead from the appropriate matchbox.\n",
    "   - After the game, beads are added or removed based on the outcome:\n",
    "     - Win: Add three beads of the colors used\n",
    "     - Draw: Add one bead of the colors used\n",
    "     - Loss: Remove one bead of the colors used\n",
    "\n",
    "Over time, MENACE learns to make better moves by adjusting the probabilities of selecting each move in different game states.\n",
    "\n",
    "## Significance\n",
    "\n",
    "MENACE is significant for several reasons:\n",
    "\n",
    "1. **Early Reinforcement Learning**: It demonstrated a simple yet effective form of reinforcement learning, a concept that would become crucial in modern AI and machine learning.\n",
    "2. **Mechanical Computation**: MENACE showed that learning algorithms could be implemented without electronic computers, emphasizing the underlying principles of machine learning.\n",
    "3. **Interpretability**: The physical nature of MENACE made it easy to understand and visualize the learning process, a quality often lacking in modern, more complex machine learning models.\n",
    "4. **Inspiration**: MENACE has inspired numerous recreations and adaptations, including digital implementations and educational tools.\n",
    "\n",
    "## Modern Relevance\n",
    "\n",
    "While MENACE itself is no longer used for practical applications, the principles it demonstrates remain relevant:\n",
    "\n",
    "1. **Reinforcement Learning**: The core idea behind MENACE is still fundamental to modern reinforcement learning algorithms used in various fields, from game playing to robotics.\n",
    "2. **Explainable AI**: As AI systems become more complex, there's a growing interest in making them more interpretable. MENACE's transparent decision-making process resonates with current efforts in explainable AI.\n",
    "3. **Educational Tool**: MENACE continues to be an excellent educational tool for introducing concepts of machine learning and reinforcement learning in an accessible, hands-on manner.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "MENACE stands as a testament to the ingenuity of early AI researchers and the timeless nature of fundamental machine learning concepts. Its simplicity, elegance, and effectiveness continue to inspire and educate, bridging the gap between the early days of AI and the cutting-edge technologies of today."
   ],
   "id": "262842cc14faff0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ],
   "id": "5db8c1c673242400",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MENACE:\n",
    "    def __init__(self, initial_beads=10):\n",
    "        self.matchboxes = {}\n",
    "        self.initial_beads = initial_beads\n",
    "        self.moves = []\n",
    "        self.first_box_beads_history = []\n",
    "        \n",
    "    def get_state(self, board):\n",
    "        return str(board.tolist())\n",
    "\n",
    "    def get_move(self, board):\n",
    "        state = self.get_state(board)\n",
    "        if state not in self.matchboxes:\n",
    "            self.matchboxes[state] = torch.full((9,), self.initial_beads, dtype=torch.float32)\n",
    "            self.matchboxes[state][board != 0] = 0\n",
    "\n",
    "        if state == '[0, 0, 0, 0, 0, 0, 0, 0, 0]':\n",
    "            print(self.matchboxes[state])\n",
    "            self.first_box_beads_history.append(self.matchboxes[state].tolist())\n",
    "            \n",
    "        probs = self.matchboxes[state] / self.matchboxes[state].sum()\n",
    "        move = torch.multinomial(probs, 1).item()\n",
    "        self.moves.append((state, move))\n",
    "        return move\n",
    "\n",
    "    def update(self, reward):\n",
    "        for state, move in self.moves:\n",
    "            self.matchboxes[state][move] += reward\n",
    "            self.matchboxes[state][move] = max(self.matchboxes[state][move], 0)\n",
    "        self.moves = []"
   ],
   "id": "f80c4521f4aa07ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def play_game(menace, player_func):\n",
    "    board = torch.zeros(9, dtype=torch.int)\n",
    "    menace_turn = random.choice([True, False])\n",
    "\n",
    "    while True:\n",
    "        if menace_turn:\n",
    "            move = menace.get_move(board)\n",
    "            board[move] = 1\n",
    "        else:\n",
    "            move = player_func(board)\n",
    "            board[move] = -1\n",
    "\n",
    "        if check_win(board):\n",
    "            return 1 if menace_turn else -1\n",
    "        if torch.all(board != 0):\n",
    "            return 0\n",
    "\n",
    "        menace_turn = not menace_turn"
   ],
   "id": "5686c716d5fd1077",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# From a board return True if there are 3 by rows, columns or diagonals.\n",
    "def check_win(board):\n",
    "    lines = [\n",
    "        [0, 1, 2], [3, 4, 5], [6, 7, 8],  # Rows\n",
    "        [0, 3, 6], [1, 4, 7], [2, 5, 8],  # Columns\n",
    "        [0, 4, 8], [2, 4, 6]  # Diagonals\n",
    "    ]\n",
    "    for line in lines:\n",
    "        if abs(board[line].sum()) == 3:\n",
    "            return True\n",
    "    return False"
   ],
   "id": "20088e7632765118",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Random moves will almost create a perfectly valid uptick in wins.\n",
    "def random_player(board):\n",
    "    valid_moves = torch.where(board == 0)[0]\n",
    "    return random.choice(valid_moves).item()"
   ],
   "id": "af5a1c96fff5f6f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialise\n",
    "menace = MENACE()\n",
    "results = []\n",
    "num_games = 10000"
   ],
   "id": "afcd607d90cf7885",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# If the result is a win (1) - add 3 beads.\n",
    "# If the result is a draw (0) - add 1 bead.\n",
    "# If the result is a loss (-1) - remove 1 bead.\n",
    "for game in range(num_games):\n",
    "    result = play_game(menace, random_player)\n",
    "    if result == 1:\n",
    "        menace.update(3)\n",
    "    elif result == 0:\n",
    "        menace.update(1)\n",
    "    else:\n",
    "        menace.update(-1)\n",
    "    results.append(result)"
   ],
   "id": "c5cd1c413c972622",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cumulative_results = torch.tensor(results).float().cumsum(dim=0)\n",
    "games_played = torch.arange(1, len(results) + 1).float()\n",
    "running_average = cumulative_results / games_played\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 16))\n",
    "\n",
    "# Plot performance\n",
    "ax1.plot(games_played, running_average)\n",
    "ax1.set_title(\"MENACE Performance Over {} Games\".format(num_games))\n",
    "ax1.set_xlabel(\"Games Played\")\n",
    "ax1.set_ylabel(\"Running Average Score\")\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot Matchbox 0\n",
    "print(menace.first_box_beads_history)\n",
    "first_box_beads_history = torch.tensor(menace.first_box_beads_history).t()\n",
    "for i in range(9):\n",
    "    ax2.plot(range(len(first_box_beads_history[i])), first_box_beads_history[i], label=f'Position {i}')\n",
    "\n",
    "ax2.set_title(\"Beads in First Matchbox for Each Position Over Time\")\n",
    "ax2.set_xlabel(\"Game Number\")\n",
    "ax2.set_ylabel(\"Number of Beads\")\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "win_rate = results.count(1) / len(results)\n",
    "draw_rate = results.count(0) / len(results)\n",
    "loss_rate = results.count(-1) / len(results)\n",
    "\n",
    "print(f\"Win rate: {win_rate:.2%}\")\n",
    "print(f\"Draw rate: {draw_rate:.2%}\")\n",
    "print(f\"Loss rate: {loss_rate:.2%}\")"
   ],
   "id": "643b1f72089d4e0c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
