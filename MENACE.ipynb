{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# MENACE: Machine Educable Noughts And Crosses Engine\n",
    "\n",
    "## Introduction\n",
    "\n",
    "MENACE (Machine Educable Noughts And Crosses Engine) is a mechanical learning machine designed by Donald Michie in 1961. It was created to demonstrate the concept of reinforcement learning, long before modern machine learning techniques were developed.\n",
    "\n",
    "## Historical Context\n",
    "\n",
    "Donald Michie (1923-2007) was a British researcher and a pioneer in artificial intelligence. He worked at Bletchley Park during World War II, contributing to the effort to break the German Enigma code alongside Alan Turing. After the war, Michie pursued a career in biology before transitioning to artificial intelligence research.\n",
    "\n",
    "MENACE was conceived during a time when computers were still in their infancy and not widely accessible. Michie's invention demonstrated that learning algorithms could be implemented without complex electronic computers, using simple mechanical means.\n",
    "\n",
    "## How MENACE Works\n",
    "\n",
    "MENACE uses a collection of matchboxes to \"learn\" how to play Tic-Tac-Toe (also known as Noughts and Crosses). Here's a brief overview of its operation:\n",
    "\n",
    "1. **Representation**: Each possible game state is represented by a matchbox.\n",
    "2. **Decision Making**: Inside each matchbox are colored beads, each color corresponding to a possible move.\n",
    "3. **Learning**: \n",
    "   - To make a move, MENACE randomly selects a bead from the appropriate matchbox.\n",
    "   - After the game, beads are added or removed based on the outcome:\n",
    "     - Win: Add three beads of the colors used\n",
    "     - Draw: Add one bead of the colors used\n",
    "     - Loss: Remove one bead of the colors used\n",
    "\n",
    "Over time, MENACE learns to make better moves by adjusting the probabilities of selecting each move in different game states.\n",
    "\n",
    "## Significance\n",
    "\n",
    "MENACE is significant for several reasons:\n",
    "\n",
    "1. **Early Reinforcement Learning**: It demonstrated a simple yet effective form of reinforcement learning, a concept that would become crucial in modern AI and machine learning.\n",
    "2. **Mechanical Computation**: MENACE showed that learning algorithms could be implemented without electronic computers, emphasizing the underlying principles of machine learning.\n",
    "3. **Interpretability**: The physical nature of MENACE made it easy to understand and visualize the learning process, a quality often lacking in modern, more complex machine learning models.\n",
    "4. **Inspiration**: MENACE has inspired numerous recreations and adaptations, including digital implementations and educational tools.\n",
    "\n",
    "## Modern Relevance\n",
    "\n",
    "While MENACE itself is no longer used for practical applications, the principles it demonstrates remain relevant:\n",
    "\n",
    "1. **Reinforcement Learning**: The core idea behind MENACE is still fundamental to modern reinforcement learning algorithms used in various fields, from game playing to robotics.\n",
    "2. **Explainable AI**: As AI systems become more complex, there's a growing interest in making them more interpretable. MENACE's transparent decision-making process resonates with current efforts in explainable AI.\n",
    "3. **Educational Tool**: MENACE continues to be an excellent educational tool for introducing concepts of machine learning and reinforcement learning in an accessible, hands-on manner.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "MENACE stands as a testament to the ingenuity of early AI researchers and the timeless nature of fundamental machine learning concepts. Its simplicity, elegance, and effectiveness continue to inspire and educate, bridging the gap between the early days of AI and the cutting-edge technologies of today."
   ],
   "id": "262842cc14faff0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as matplotlib_pyplot\n",
    "import numpy as numpy"
   ],
   "id": "5db8c1c673242400",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Each MENACE mathbox has a state of the board 0/1 for each position with 10 initial beads.\n",
    "# Matchboxes is a hash of board states (0-8) and a tensor of the number of beads. \n",
    "# A move requires the state of the board.\n",
    "class MENACE:\n",
    "    def __init__(self, initial_beads=10):\n",
    "        self.matchboxes = {}\n",
    "        self.initial_beads = initial_beads\n",
    "        self.moves = []\n",
    "        self.first_box_beads_history = []\n",
    "\n",
    "    def get_state(self, board):\n",
    "        return ','.join(map(str, board))\n",
    "    \n",
    "    def reset_history(self):\n",
    "        self.first_box_beads_history = []\n",
    "\n",
    "    def get_move(self, board):\n",
    "        state = self.get_state(board)\n",
    "        if state not in self.matchboxes:\n",
    "            self.matchboxes[state] = [self.initial_beads if cell == 0 else 0 for cell in board]\n",
    "\n",
    "        # Record a history of the first move of the first matchbox.\n",
    "        if state == '0,0,0,0,0,0,0,0,0':\n",
    "            self.first_box_beads_history.append(self.matchboxes[state][:])\n",
    "\n",
    "        # If it runs out of beads - just pick a random move.\n",
    "        total_beads = sum(self.matchboxes[state])\n",
    "        if total_beads == 0:\n",
    "            return random.choice([i for i, beads in enumerate(self.matchboxes[state]) if beads == 0])\n",
    "        else:\n",
    "            # Select a move 0-8, using the number of beads left to weight the probability.\n",
    "            move = random.choices(range(9), weights=self.matchboxes[state])[0]\n",
    "            self.moves.append((state, move))\n",
    "            return move\n",
    "\n",
    "    # Set reward - min value 0 beads.\n",
    "    def update(self, reward):\n",
    "        for state, move in self.moves:\n",
    "            self.matchboxes[state][move] += reward\n",
    "            self.matchboxes[state][move] = max(self.matchboxes[state][move], 0)\n",
    "        self.moves = []"
   ],
   "id": "f80c4521f4aa07ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# From a board state, make a random move.\n",
    "# Random moves will almost create a perfectly valid uptick in wins.\n",
    "class RandomPlayer:\n",
    "    def __init__(self):\n",
    "        self.moves = []\n",
    "\n",
    "    def get_move(self, board):\n",
    "        valid_moves = [i for i, cell in enumerate(board) if cell == 0]\n",
    "        move = random.choice(valid_moves)\n",
    "        self.moves.append((self.get_state(board), move))\n",
    "        return move\n",
    "\n",
    "    # Random player doesn't learn, so we just clear the moves\n",
    "    def update(self, reward):\n",
    "        self.moves = []\n",
    "\n",
    "    def get_state(self, board):\n",
    "        return ','.join(map(str, board))"
   ],
   "id": "2a3ceb67f2fb34df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# A board has 0-8 spaces in a tic-tac-toe board - winning is rows, columns or diagonals.\n",
    "class Board:\n",
    "    def __init__(self):\n",
    "        self.states = [0] * 9\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.states[index]\n",
    "\n",
    "    def __setitem__(self, index, value):\n",
    "        self.states[index] = value\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.states)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.states)        \n",
    "    \n",
    "    # From a board return True if there are 3 by rows, columns or diagonals.\n",
    "    def check_win(self):\n",
    "        lines = [\n",
    "            [0, 1, 2], [3, 4, 5], [6, 7, 8],  # Rows\n",
    "            [0, 3, 6], [1, 4, 7], [2, 5, 8],  # Columns\n",
    "            [0, 4, 8], [2, 4, 6]              # Diagonals\n",
    "        ]\n",
    "        for line in lines:\n",
    "            if self.states[line[0]] != 0 and self.states[line[0]] == self.states[line[1]] == self.states[line[2]]:\n",
    "                return True\n",
    "        return False"
   ],
   "id": "2eb5e74a77a01957",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create empty board, MENACE always goes first.\n",
    "# Alternately, get a MENACE move, get a player move.\n",
    "# Check for a win - return 1 if MENACE one -1 if player has one.\n",
    "def play_game(menace, player):\n",
    "    board = Board()\n",
    "    menace_turn = True\n",
    "\n",
    "    while True:\n",
    "        if menace_turn:\n",
    "            move = menace.get_move(board)\n",
    "            board[move] = 1\n",
    "        else:\n",
    "            move = player.get_move(board)\n",
    "            board[move] = -1\n",
    "\n",
    "        if board.check_win():\n",
    "            return 1 if menace_turn else -1\n",
    "        if all(cell != 0 for cell in board):\n",
    "            return 0\n",
    "\n",
    "        menace_turn = not menace_turn"
   ],
   "id": "5686c716d5fd1077",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T04:53:38.115397Z",
     "start_time": "2024-09-30T04:53:27.598216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialise\n",
    "menace = MENACE()\n",
    "player = RandomPlayer()\n",
    "results = []\n",
    "num_games = 200"
   ],
   "id": "afcd607d90cf7885",
   "outputs": [],
   "execution_count": 169
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# If the result is a win (1) - add 3 beads.\n",
    "# If the result is a draw (0) - add 1 bead.\n",
    "# If the result is a loss (-1) - remove 1 bead.\n",
    "for game in range(num_games):\n",
    "    result = play_game(menace, player)\n",
    "    if result == 1:\n",
    "        menace.update(3)\n",
    "    elif result == 0:\n",
    "        menace.update(1)\n",
    "    else:\n",
    "        menace.update(-1)\n",
    "    results.append(result)"
   ],
   "id": "c5cd1c413c972622",
   "outputs": [],
   "execution_count": 168
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Assuming 'results' is a list of game outcomes (1 for win, 0 for draw, -1 for loss)\n",
    "# and 'menace' is your MENACE instance\n",
    "cumulative_results = numpy.cumsum(results)\n",
    "games_played = numpy.arange(1, len(results) + 1)\n",
    "running_average = cumulative_results / games_played\n",
    "\n",
    "fig, (ax1, ax2, ax3) = matplotlib_pyplot.subplots(3, 1, figsize=(12, 16))\n",
    "\n",
    "# Plot performance\n",
    "ax1.plot(games_played, running_average)\n",
    "ax1.set_title(f\"MENACE Performance Over {len(results)} Games\")\n",
    "ax1.set_xlabel(\"Games Played\")\n",
    "ax1.set_ylabel(\"Running Average Score\")\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot Matchbox 0\n",
    "first_box_beads_history = numpy.array(menace.first_box_beads_history).T\n",
    "for i in range(9):\n",
    "    ax2.plot(range(len(first_box_beads_history[i])), first_box_beads_history[i], label=f'Position {i}')\n",
    "\n",
    "ax2.set_title(\"Beads in First Matchbox for Each Position Over Time\")\n",
    "ax2.set_xlabel(\"Game Number\")\n",
    "ax2.set_ylabel(\"Number of Beads\")\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "# Plot against tic-tac-toe\n",
    "final_beads = menace.matchboxes['0,0,0,0,0,0,0,0,0']\n",
    "beads_array = numpy.array(final_beads).reshape(3, 3)\n",
    "\n",
    "ax3.imshow(beads_array, cmap='YlOrRd')\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax3.text(j, i, f'{beads_array[i, j]:.1f}', ha='center', va='center', color='black', fontweight='bold')\n",
    "\n",
    "ax3.set_xticks([])\n",
    "ax3.set_yticks([])\n",
    "ax3.set_title('Number of Beads for First Move')\n",
    "\n",
    "for i in range(4):\n",
    "    ax3.axhline(i - 0.5, color='black', linewidth=2)\n",
    "    ax3.axvline(i - 0.5, color='black', linewidth=2)\n",
    "\n",
    "matplotlib_pyplot.tight_layout()\n",
    "\n",
    "win_rate = results.count(1) / len(results)\n",
    "draw_rate = results.count(0) / len(results)\n",
    "loss_rate = results.count(-1) / len(results)\n",
    "\n",
    "print(f\"Win rate: {win_rate:.2%}\")\n",
    "print(f\"Draw rate: {draw_rate:.2%}\")\n",
    "print(f\"Loss rate: {loss_rate:.2%}\")"
   ],
   "id": "643b1f72089d4e0c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
